{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28130854-a067-4221-ba11-c46c1f4a4bf6",
   "metadata": {},
   "source": [
    "<font size=\"5\">**ABHISHEK KUMAR SINGH**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571eddcc-4a5d-4626-a520-e949ec9c1893",
   "metadata": {},
   "source": [
    "<font size=\"5\">**2K19/CO/021**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4938ed-649d-499b-851a-ded78b46388f",
   "metadata": {},
   "source": [
    "**<font size=\"8\"><center>EXPERIMENT - 8</center></font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc321b-767f-434b-9b5a-ada83f9eb41d",
   "metadata": {},
   "source": [
    "**AIM:** To implement Friedman test and Wilcoxon test in python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e6050",
   "metadata": {},
   "source": [
    "[Link of Dataset](https://www.kaggle.com/chirin/africa-economic-banking-and-systemic-crisis-data/version/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee86d2-43eb-4d48-8bcf-7f88ec54df3b",
   "metadata": {},
   "source": [
    "**THEORY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e9e2d",
   "metadata": {},
   "source": [
    "**P-value** \n",
    "\n",
    "The P value, or calculated probability, is the probability of finding the observed, or more extreme, results when the null hypothesis (H 0) of a study question is true — the definition of ‘extreme’ depends on how the hypothesis is being tested.\n",
    "If the P value is less than the chosen significance level then we reject the null hypothesis i.e. accept that our sample gives reasonable evidence to support the alternative hypothesis. It does NOT imply a “meaningful” or “important” difference; that is for us to decide when considering the real-world relevance of our result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291a38a",
   "metadata": {},
   "source": [
    "**Friedman Test** \n",
    "\n",
    "It is a non-parametric test alternative to the one way ANOVA with repeated measures. It tries to determine if subjects changed significantly across occasions/conditions. For example:- Problem-solving ability of a set of people is the same or different in Morning, Afternoon, Evening. It is used to test for differences between groups when the dependent variable is ordinal. This test is particularly useful when the sample size is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0f54f",
   "metadata": {},
   "source": [
    "**Post Hoc Analysis** \n",
    "\n",
    "We can find out whether there is a difference in any given pair of experimental conditions if the null hypothesis is rejected using the Post Hoc analysis which can be done using Wilcoxon signed-rank test, Conover’s test etc.. In Wilcoxon test, we can get the results for all pairs also but we will have to make a Bonferroni correction which will change the level of significance to Given level of significance/total number of pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c3594",
   "metadata": {},
   "source": [
    "**Wilcoxon signed-rank test**\n",
    "\n",
    "The Wilcoxon signed-rank test is the nonparametric test equivalent to the dependent t-test. As the Wilcoxon signed-rank test does not assume normality in the data, it can be used when this assumption has been violated and the use of the dependent t-test is inappropriate. It is used to compare two sets of scores that come from the same participants. This can occur when we wish to investigate any change in scores from one time point to another, or when individuals are subjected to more than one condition.\n",
    "\n",
    "For example, Wilcoxon signed-rank test can be used to understand whether there was a difference in smokers' daily cigarette consumption before and after a 6 week hypnotherapy programme (i.e., the dependent variable would be \"daily cigarette consumption\", and the two related groups would be the cigarette consumption values \"before\" and \"after\" the hypnotherapy programme). Wilcoxon signed-rank test can also be used to understand whether there was a difference in reaction times under two different lighting conditions (i.e., the dependent variable would be \"reaction time\", measured in milliseconds, and the two related groups would be reaction times in a room using \"blue light\" versus \"red light\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec60199-356e-4056-a36b-1bfdf4c8b232",
   "metadata": {},
   "source": [
    "**CODE AND OUTPUT:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73623d",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f4aee7-bcb2-4e6b-8524-3cd4ee78b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b8fb5",
   "metadata": {},
   "source": [
    "**Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5821e6a9-a937-47dd-8e9d-3ed2e9f8fb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>cc3</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>systemic_crisis</th>\n",
       "      <th>exch_usd</th>\n",
       "      <th>domestic_debt_in_default</th>\n",
       "      <th>sovereign_external_debt_default</th>\n",
       "      <th>gdp_weighted_default</th>\n",
       "      <th>inflation_annual_cpi</th>\n",
       "      <th>independence</th>\n",
       "      <th>currency_crises</th>\n",
       "      <th>inflation_crises</th>\n",
       "      <th>banking_crisis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1870</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.441456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.149140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.718593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1873</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.203897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1874</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.848561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_crisis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case  cc3  country  year  systemic_crisis  exch_usd  \\\n",
       "0     1  DZA  Algeria  1870                1  0.052264   \n",
       "1     1  DZA  Algeria  1871                0  0.052798   \n",
       "2     1  DZA  Algeria  1872                0  0.052274   \n",
       "3     1  DZA  Algeria  1873                0  0.051680   \n",
       "4     1  DZA  Algeria  1874                0  0.051308   \n",
       "\n",
       "   domestic_debt_in_default  sovereign_external_debt_default  \\\n",
       "0                         0                                0   \n",
       "1                         0                                0   \n",
       "2                         0                                0   \n",
       "3                         0                                0   \n",
       "4                         0                                0   \n",
       "\n",
       "   gdp_weighted_default  inflation_annual_cpi  independence  currency_crises  \\\n",
       "0                   0.0              3.441456             0                0   \n",
       "1                   0.0             14.149140             0                0   \n",
       "2                   0.0             -3.718593             0                0   \n",
       "3                   0.0             11.203897             0                0   \n",
       "4                   0.0             -3.848561             0                0   \n",
       "\n",
       "   inflation_crises banking_crisis  \n",
       "0                 0         crisis  \n",
       "1                 0      no_crisis  \n",
       "2                 0      no_crisis  \n",
       "3                 0      no_crisis  \n",
       "4                 0      no_crisis  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"african_crises.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8535e68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1059 entries, 0 to 1058\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   case                             1059 non-null   int64  \n",
      " 1   cc3                              1059 non-null   object \n",
      " 2   country                          1059 non-null   object \n",
      " 3   year                             1059 non-null   int64  \n",
      " 4   systemic_crisis                  1059 non-null   int64  \n",
      " 5   exch_usd                         1059 non-null   float64\n",
      " 6   domestic_debt_in_default         1059 non-null   int64  \n",
      " 7   sovereign_external_debt_default  1059 non-null   int64  \n",
      " 8   gdp_weighted_default             1059 non-null   float64\n",
      " 9   inflation_annual_cpi             1059 non-null   float64\n",
      " 10  independence                     1059 non-null   int64  \n",
      " 11  currency_crises                  1059 non-null   int64  \n",
      " 12  inflation_crises                 1059 non-null   int64  \n",
      " 13  banking_crisis                   1059 non-null   object \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 116.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f576315",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1bd2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 2:12]\n",
    "y = data.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167f8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_int = list(x.select_dtypes(int).columns)\n",
    "le=LabelEncoder()\n",
    "y = pd.DataFrame(le.fit_transform(np.array(y.values.ravel())), columns=[\"BankCrisis\"])\n",
    "for col in col_names_int:\n",
    "    x[col] = le.fit_transform(x[col].astype(str))\n",
    "    y = pd.DataFrame(le.fit_transform(np.array(y.values.ravel())), columns=[\"RainTomorrow\"])\n",
    "df1= x[col_names_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7ed72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(x.select_dtypes(float).columns)\n",
    "scaler = StandardScaler()\n",
    "df2 = scaler.fit_transform(x.select_dtypes(float))\n",
    "df2 = pd.DataFrame(df2, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3083936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join features\n",
    "\n",
    "x = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f1c2d",
   "metadata": {},
   "source": [
    "**Building the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e45d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsagg = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39089050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "results30=[]\n",
    "for i in range(30): \n",
    "    kf = KFold(10, shuffle=True, random_state=i)\n",
    "    results = []\n",
    "    for l_train, l_valid in kf.split(x):\n",
    "        x_train, x_valid = x.iloc[l_train], x.iloc[l_valid] \n",
    "        y_train, y_valid = y.iloc[l_train], y.iloc[l_valid]\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=10)\n",
    "        knn.fit(x_train, y_train.values.ravel())\n",
    "        y_pred = knn.predict(x_valid)\n",
    "        acc = accuracy_score(y_valid.values.ravel(), y_pred)\n",
    "        results.append(acc)\n",
    "    \n",
    "    results30.append(np.mean(results))\n",
    "\n",
    "resultsagg[\"KNN\"]=results30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca78c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "results30=[]\n",
    "for i in range(30):\n",
    "    kf = KFold(10, shuffle=True, random_state=i)\n",
    "    results = []\n",
    "    for l_train, l_valid in kf.split(x):\n",
    "        x_train, x_valid = x.iloc[l_train], x.iloc[l_valid] \n",
    "        y_train, y_valid = y.iloc[l_train], y.iloc[l_valid]\n",
    "\n",
    "        log = LogisticRegression(random_state=i, solver='liblinear')\n",
    "        log.fit(x_train, y_train.values.ravel())\n",
    "        y_pred = log.predict(x_valid)\n",
    "        acc = accuracy_score(y_valid.values.ravel(), y_pred)\n",
    "        results.append(acc)\n",
    "    results30.append(np.mean(results))\n",
    "\n",
    "resultsagg[\"LogisticRegression\"]=results30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70554a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "results30=[]\n",
    "for i in range(30):\n",
    "    kf = KFold(10, shuffle=True, random_state=i)\n",
    "    results = []\n",
    "    for l_train, l_valid in kf.split(x):\n",
    "        x_train, x_valid = x.iloc[l_train], x.iloc[l_valid] \n",
    "        y_train, y_valid = y.iloc[l_train], y.iloc[l_valid]\n",
    "\n",
    "        nb = GaussianNB()\n",
    "        nb.fit(x_train, y_train.values.ravel())\n",
    "        y_pred = nb.predict(x_valid)\n",
    "        acc = accuracy_score(y_valid.values.ravel(), y_pred)\n",
    "        results.append(acc)\n",
    "    results30.append(np.mean(results))\n",
    "\n",
    "resultsagg[\"NaiveBayes\"]=results30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3898622c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.9079008685235102\n",
      "LogisticRegression: 0.911137466307278\n",
      "NaiveBayes: 0.9113932315064392\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN:\",  resultsagg[\"KNN\"].mean())\n",
    "print(\"LogisticRegression:\",  resultsagg[\"LogisticRegression\"].mean())\n",
    "print(\"NaiveBayes:\",  resultsagg[\"NaiveBayes\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d3fc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>NaiveBayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.908437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.908455</td>\n",
       "      <td>0.911267</td>\n",
       "      <td>0.909380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904600</td>\n",
       "      <td>0.911240</td>\n",
       "      <td>0.910305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.910261</td>\n",
       "      <td>0.910234</td>\n",
       "      <td>0.910243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.906478</td>\n",
       "      <td>0.912165</td>\n",
       "      <td>0.913109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.904663</td>\n",
       "      <td>0.911258</td>\n",
       "      <td>0.912192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.908410</td>\n",
       "      <td>0.912183</td>\n",
       "      <td>0.912156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.910279</td>\n",
       "      <td>0.911231</td>\n",
       "      <td>0.911231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.909362</td>\n",
       "      <td>0.910305</td>\n",
       "      <td>0.910314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.909299</td>\n",
       "      <td>0.911231</td>\n",
       "      <td>0.910296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.909335</td>\n",
       "      <td>0.911204</td>\n",
       "      <td>0.911222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.905606</td>\n",
       "      <td>0.911258</td>\n",
       "      <td>0.911267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.904600</td>\n",
       "      <td>0.911195</td>\n",
       "      <td>0.914016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.906568</td>\n",
       "      <td>0.910350</td>\n",
       "      <td>0.911294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.906496</td>\n",
       "      <td>0.911204</td>\n",
       "      <td>0.910279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.911222</td>\n",
       "      <td>0.911213</td>\n",
       "      <td>0.913127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.904609</td>\n",
       "      <td>0.911204</td>\n",
       "      <td>0.914016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.906478</td>\n",
       "      <td>0.912129</td>\n",
       "      <td>0.908347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.911267</td>\n",
       "      <td>0.912201</td>\n",
       "      <td>0.909380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.905571</td>\n",
       "      <td>0.911231</td>\n",
       "      <td>0.910288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.906496</td>\n",
       "      <td>0.911213</td>\n",
       "      <td>0.912165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.910296</td>\n",
       "      <td>0.911231</td>\n",
       "      <td>0.911222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.905580</td>\n",
       "      <td>0.911240</td>\n",
       "      <td>0.915040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.910323</td>\n",
       "      <td>0.911267</td>\n",
       "      <td>0.913163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.909317</td>\n",
       "      <td>0.910225</td>\n",
       "      <td>0.911186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.906514</td>\n",
       "      <td>0.910305</td>\n",
       "      <td>0.915040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.907493</td>\n",
       "      <td>0.910305</td>\n",
       "      <td>0.910314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.907466</td>\n",
       "      <td>0.911222</td>\n",
       "      <td>0.913100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.909344</td>\n",
       "      <td>0.911222</td>\n",
       "      <td>0.910279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.910323</td>\n",
       "      <td>0.911276</td>\n",
       "      <td>0.909389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         KNN  LogisticRegression  NaiveBayes\n",
       "0   0.910314            0.910314    0.908437\n",
       "1   0.908455            0.911267    0.909380\n",
       "2   0.904600            0.911240    0.910305\n",
       "3   0.910261            0.910234    0.910243\n",
       "4   0.906478            0.912165    0.913109\n",
       "5   0.904663            0.911258    0.912192\n",
       "6   0.908410            0.912183    0.912156\n",
       "7   0.910279            0.911231    0.911231\n",
       "8   0.909362            0.910305    0.910314\n",
       "9   0.909299            0.911231    0.910296\n",
       "10  0.909335            0.911204    0.911222\n",
       "11  0.905606            0.911258    0.911267\n",
       "12  0.904600            0.911195    0.914016\n",
       "13  0.906568            0.910350    0.911294\n",
       "14  0.906496            0.911204    0.910279\n",
       "15  0.911222            0.911213    0.913127\n",
       "16  0.904609            0.911204    0.914016\n",
       "17  0.906478            0.912129    0.908347\n",
       "18  0.911267            0.912201    0.909380\n",
       "19  0.905571            0.911231    0.910288\n",
       "20  0.906496            0.911213    0.912165\n",
       "21  0.910296            0.911231    0.911222\n",
       "22  0.905580            0.911240    0.915040\n",
       "23  0.910323            0.911267    0.913163\n",
       "24  0.909317            0.910225    0.911186\n",
       "25  0.906514            0.910305    0.915040\n",
       "26  0.907493            0.910305    0.910314\n",
       "27  0.907466            0.911222    0.913100\n",
       "28  0.909344            0.911222    0.910279\n",
       "29  0.910323            0.911276    0.909389"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsagg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d329b933",
   "metadata": {},
   "source": [
    "**Friedman Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "598f36cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FriedmanchisquareResult(statistic=28.288135593220336, pvalue=7.199617174126064e-07)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.friedmanchisquare(resultsagg['KNN'], resultsagg['LogisticRegression'], resultsagg['NaiveBayes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a4fdbd",
   "metadata": {},
   "source": [
    "There was a statistically significant difference in accuracy_score depending on which type of machine learning model was trained to make predictions, χ2(2) = 28.2881, p = 7.1996e-07."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a1de8b",
   "metadata": {},
   "source": [
    "**Post Hoc Tests**\n",
    "\n",
    "To examine where the differences actually occur, we need to run separate Wilcoxon signed-rank tests on the different combinations of related groups.\n",
    "\n",
    "We need to use a Bonferroni adjustment on the results of the Wilcoxon tests because we are making multiple comparisons, which makes it more likely that we will declare a result significant when we should not (a Type I error). Luckily, the Bonferroni adjustment is very easy to calculate; simply take the significance level initially using (in this case, 0.05) and divide it by the number of tests we are running. So in this example, we have a new significance level of 0.05/3 = 0.017. This means that if the p value is larger than 0.017, we do not have a statistically significant result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48175ce6",
   "metadata": {},
   "source": [
    "**Wilcoxon signed-rank test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779a5988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3.0, pvalue=3.50805501501122e-06)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.wilcoxon(resultsagg['KNN'], resultsagg['LogisticRegression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52a241a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=172.0, pvalue=0.3251157886671938)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.wilcoxon(resultsagg['LogisticRegression'], resultsagg['NaiveBayes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9878ed9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=29.0, pvalue=2.839269517405251e-05)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.wilcoxon(resultsagg['KNN'], resultsagg['NaiveBayes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe803e8",
   "metadata": {},
   "source": [
    "We can see that at the p < 0.017 significance level, accuracy_score between KNN and Logistic Regression or between KNN and Naive Bayes were statistically significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e1e0c",
   "metadata": {},
   "source": [
    "There was a statistically significant difference in accuracy_score depending on which type of machine learning model was trained to make predictions, χ2(2) = 28.2881, p = 7.1996e-07.\n",
    "\n",
    "Post hoc analysis with Wilcoxon signed-rank tests was conducted with a Bonferroni correction applied, resulting in a significance level set at p < 0.017. \n",
    "\n",
    "There was no significant difference between the Logistic Regression and Naive Bayes models.\n",
    "However, there were statistically significant differences between the KNN and Logistic Regression models or between KNN and Naive Bayes models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e99cd-cc0d-4ae3-9840-ad8b7c6f3edd",
   "metadata": {},
   "source": [
    "**LEARNING OUTCOMES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70984b-b4d2-471c-bd9e-45ccede32b7f",
   "metadata": {},
   "source": [
    "We learnt about Friedman test and Wilcoxon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1b9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
